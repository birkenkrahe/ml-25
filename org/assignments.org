#+title: Assignments
#+author: Marcus Birkenkrahe
#+subtitle: DSC 305
#+SEQ_TODO: TODO IN_PROGRESS | DONE
#+startup: overview hideblocks indent entitiespretty: 
#+property: header-args:C :main yes :includes <stdio.h> :results output :exports both: 
#+property: header-args:python :session *Python* :python python3 :results output :exports both: 
#+src R :file :session *R* :results graphics output file :exports both: 
#+property: header-args:C++ :main yes :includes <iostream> :results output :exports both: 
* DataCamp assignments:

- Schedule
  #+name: datacamp
  | Week | DataCamp course: chapter                                      | Date   |
  |------+---------------------------------------------------------------+--------|
  |    1 | Understanding ML: What is ML?                                 | Jan 21 |
  |    2 | Understanding ML: ML Models                                   | Jan 28 |
  |    3 | Understanding ML: Deep Learning                               | Feb 4  |
  |------+---------------------------------------------------------------+--------|
  |    4 | Supervised Learning in R: k-Nearest Neighbors                 | Feb 11 |
  |    5 | Supervised Learning in R: Naive Bayes                         | Feb 18 |
  |    6 | Supervised Learning in R: Logistic Regression                 | Feb 25 |
  |    7 | Supervised Learning in R: Classification Trees                | Mar 4  |
  |------+---------------------------------------------------------------+--------|
  |    8 | Unsupervised Learning in R: Introduction                      |        |
  |    9 | Unsupervised Learning in R: Hierarchical clustering           |        |
  |   10 | Unsupervised Learning in R: Dimensionality reduction with PCA |        |
  |   11 | Unsupervised Learning in R: Case study - Mammography          |        |
  |   10 | Fraud Detection in R: Introduction and Motivation             |        |
  |   11 | Fraud Detection in R: Social Network Analysis                 |        |
  |   12 | MLOps Concepts: Introduction to MLOps                         |        |

- Bonus:
  | DataCamp course: chapter                                   | Date  | Bonus |
  |------------------------------------------------------------+-------+-------|
  | Fraud Detection in R: Imbalanced class distributions       | May 9 |    10 |
  | Fraud Detection in R: Digit analysis and robust statistics | May 9 |    10 |
  | MLOps Concepts: Design and Development                     | May 9 |     5 |
  | MLOps Concepts: Deploying ML into Production               | May 9 |     5 |
  | MLOps Concepts: Maintaining ML in Production               | May 9 |     5 |

- Assignment text:
  #+begin_quote
  In this course, (most of) your home assignments will come from
  DataCamp including: 1) A no-code introduction to machine
  learning, 2) supervised learning methods, 3) unsupervised learning
  methods, 4) fraud detection applications, and 5) MLOps concepts.

  Three courses are complete, while two courses are only partially
  included, and you can complete them for extra credit.

  You will make the most of these online courses if you work through
  each lesson and exercise on your own using an interactive
  computational notebook - this will take more than the minimum time,
  especially if you research your own open questions. It goes without
  saying that you should not attempt to complete these lessons in the
  last minute.

  If you miss the deadline, your point result is reduced by 1 point
  for every day of late submission (that means that you get 10...0
  points when completing 0...10 days after the deadline).

  *No submission.* Complete the course on the DataCamp platform, and I
  will update the gradebook manually at regular intervals.
  #+end_quote

- Understanding ML (Jan 21, Jan 28, Feb 4)
  #+begin_quote
  The first three courses, "Understanding Machine Learning", are
  no-code lessons only, and provide an application-oriented,
  conceptual overview of the field at large. This third lesson is
  concerned with ML methods based on neural network architectures,
  which we will not cover in the course (or perhaps only very little).
  #+end_quote
* Fitting a model to obtain g

- In class, we computed the value of the gravitational constant $g$
  using this table of observations, and the well-known kinematic
  formula x = 1/2 g t^2.

  | Distance [m] | Time [s] |
  |--------------+----------|
  |         1.86 |        1 |
  |         7.42 |        2 |
  |        16.70 |        3 |
  |        29.68 |        4 |

- Create a linear model using R's =lm= function to predict the falling
  =distance= at =time= = 5 seconds.

- Test the prediction against the exact value for g at that time.

- Submit your results in the form of a notebook. If you worked in an
  online notebook, submit the URL and make sure that I can access the
  file (don't make me have to ask you, please).

** Solution

1) Compute the exact value of g using the formula and the data for
   =distance= vs. =time=:

   #+begin_src R

   #+end_src

2) Create a linear =model= based on the observations of =distance=
   vs. =time= only:
   
   #+begin_src R
   
   #+end_src
